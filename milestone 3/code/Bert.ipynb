{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import dataset\n",
    "from datasets import Dataset # converting df to transformer dataset\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNC\n",
      "\ttrain      has 39978 rows and shapes (39978, 5).\n",
      "\tvalidation has  4997 rows and shapes (4997, 5).\n",
      "\ttest       has  4997 rows and shapes (4997, 5).\n",
      "LIAR\n",
      "\ttrain      has 10240 rows and shapes (10240, 14).\n",
      "\tvalidation has  1284 rows and shapes (1284, 14).\n",
      "\ttest       has  1267 rows and shapes (1267, 14).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_id = 0 if str(device) == 'cuda' else -1\n",
    "\n",
    "FNC_PATH=\"../../milestone 2/baseline/dataset/FNC-1\"\n",
    "LIAR_PATH=\"../../milestone 2/baseline/dataset/LIAR/\"\n",
    "\n",
    "ds = dataset(FNC_PATH=FNC_PATH, LIAR_PATH=LIAR_PATH, word2vec=False)\n",
    "train_df, val_df, test_df = ds(dataset=\"LIAR\", all = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = pipeline('fill-mask', model='bert-base-cased', device=device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils \n",
    "def get_prediction(bert_respond)->int:\n",
    "    return 1 if sorted(bert_respond, key = lambda x: x['score'])[-1]['token_str'] == \"real\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df['statement']\n",
    "train_y = train_df['label'].astype(int).to_numpy()\n",
    "\n",
    "val_X = val_df['statement']\n",
    "val_y = val_df['label'].astype(int).to_numpy()\n",
    "\n",
    "test_X = test_df['statement']\n",
    "test_y = test_df['label'].astype(int).to_numpy()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  filtered 1 sample(s), remain 10239 samples.\n",
      "Val dataset:  filtered 0 sample(s), remain 1284 samples.\n",
      "Test dataset:  filtered 1 sample(s), remain 1266 samples.\n"
     ]
    }
   ],
   "source": [
    "def filter_long_sample(X_df, y_df, print_head = \"\"):\n",
    "    tokenized_X = X_df.apply(lambda x: tokenizer(x))\n",
    "    too_long    = tokenized_X.apply(lambda x: len(x['input_ids']) > 512)\n",
    "    print(f\"{print_head} filtered {sum(too_long)} sample(s), remain {sum(~too_long)} samples.\")\n",
    "    return X_df[~too_long], y_df[~too_long]\n",
    "\n",
    "train_X, train_y = filter_long_sample(train_X, train_y, print_head=\"Train dataset: \")\n",
    "val_X, val_y     = filter_long_sample(val_X, val_y, print_head=\"Val dataset: \")\n",
    "test_X, test_y   = filter_long_sample(test_X, test_y, print_head=\"Test dataset: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic bert without training\n",
    "result = test_X.apply(lambda x: bert_model(f\"{x} This is a [MASK] news.\", targets=[\"real\", \"fake\"]) )\n",
    "prediction = result.apply(lambda x: get_prediction(x) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Bert Result: \n",
      "\tAccuracy: 0.4115\n",
      "\tF1 score: 0.5178\n"
     ]
    }
   ],
   "source": [
    "print(f\"Basic Bert Result: \")\n",
    "print(f\"\\tAccuracy: {accuracy_score(test_y, prediction.values):.4f}\")\n",
    "print(f\"\\tF1 score: {f1_score(test_y, prediction.values):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# training a Bert\n",
    "classification_head_bert = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/10239 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10239/10239 [00:11<00:00, 904.15 examples/s]\n",
      "Map: 100%|██████████| 1284/1284 [00:01<00:00, 914.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "def tokenizer_function(row):\n",
    "    result = tokenizer(row[\"text\"], padding = \"max_length\", truncation = True, max_length = tokenizer.model_max_length)\n",
    "    return result\n",
    "\n",
    "data = {\"text\" : train_X,\n",
    "        \"label\" : train_y}\n",
    "train_dataset = Dataset.from_dict(data)\n",
    "train_dataset = train_dataset.map( tokenizer_function )\n",
    "\n",
    "data = {\"text\" : val_X,\n",
    "        \"label\" : val_y}\n",
    "val_dataset = Dataset.from_dict(data)\n",
    "val_dataset = val_dataset.map( tokenizer_function )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    probabilities, labels = eval_pred\n",
    "    index = np.argmax(probabilities, axis = 1)\n",
    "    accuracy = np.mean(index == labels)\n",
    "\n",
    "    f1 = f1_score(labels, index)\n",
    "    return {\"accuracy\": accuracy, \"f1 score\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    output_dir=\"training\",\n",
    "    learning_rate=5e-05,\n",
    "    num_train_epochs=3.0,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    full_determinism=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=classification_head_bert,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3840 [06:48<436:02:08, 408.89s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
